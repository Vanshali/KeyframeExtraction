# A Multi-Scale Attention Framework for Automated Polyp Localization and Keyframe Extraction From Colonoscopy Videos

Paper Link: [https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10268934](https://ieeexplore.ieee.org/abstract/document/10268934/)

## 1. Introduction
Colonoscopy video acquisition has been tremendously increased for retrospective analysis, comprehensive inspection, and detection of polyps to diagnose colorectal cancer (CRC). However, extracting meaningful clinical information from
colonoscopy videos requires an enormous amount of reviewing time, which burdens the surgeons considerably. To reduce the manual efforts, we propose a first end-to-end automated multi-stage deep learning framework to extract an adequate number of clinically significant frames, i.e., keyframes from colonoscopy videos. The proposed framework comprises multiple stages that employ different deep learning models to select keyframes, which are high-quality, non-redundant polyp frames capturing multi-views of polyps. In one of the stages of our framework, we also propose a novel multi-scale attention-based model, **YcOLOn**, for polyp localization, which generates ROI and prediction scores crucial for obtaining keyframes. 

## 2. Framework Overview
![Flowchart depicting the role of different stages in the proposed work](figures/framework.png)
*Figure 1:  Flowchart depicting the role of different stages in the proposed work*

## 3. YcOLOn Architecture


This repository will be updated soon!
